{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8d00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15669e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('movie_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d274a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = reviews_df.pop('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b5e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20612531",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = tf.data.Dataset.from_tensor_slices((reviews_df.values, label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b477fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw_count = label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6347ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05577be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = ds_raw.shuffle(ds_raw_count, reshuffle_each_iteration = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84fdd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = int(0.5 * ds_raw_count)\n",
    "train_count = int(0.8 * (ds_raw_count - test_count))\n",
    "valid_count = int(ds_raw_count - test_count - train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2880280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000, 25000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count, valid_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5009bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_raw = ds_raw.take(test_count)\n",
    "ds_train_and_valid_raw = ds_raw.skip(test_count)\n",
    "ds_train_raw = ds_train_and_valid_raw.take(train_count)\n",
    "ds_valid_raw = ds_train_and_valid_raw.skip(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62524e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3624ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "word_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5ee5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in ds_train_raw.as_numpy_iterator():\n",
    "    words = tokenizer.tokenize(review[0][0])\n",
    "    word_counts.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2228241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'When I fist watched the movie, I said to myself, \"so a film can be made like this.\" Wong Kar Wai\\'s gorgeous poetic love story captured me throughout and even after the film. I must admit this is one of the best love movies, maybe the best of all, I have ever watched. The content and the form overlaps perfectly. As watching the secret love we see the characters in bounded frames that limits their movements as well as their feelings. Beautiful camera angles and the lighting makes the feelings and the blues even touchable. I want to congratulate Christopher Doyle and Pin Bing Lee for their fantastic cinematography which creates the mood for love. Also the music defines the sadness of the love which plays along the beautiful slow motion frames and shows the characters in despairing moods. And of course the performances of the actors which makes the love so real. Eventually, all the elements in the film combined in a perfect way under the direction of WKW and give the audience the feeling called love.' 1\n",
      "b'Heather Graham couldn\\'t play a convincing lesbian if her life depended on it. Who do the producers of the movie think they are? the ABSOLUTE WORST, most UNREALISTIC movie i\\'ve seen in as long as i can remember. This movie is so bad that i felt compelled to sign-up on IMDb and make sure the rating of this \"film\" drops.<br /><br />omg i\\'m Heather Graham, i just kissed a drunk chick, so while she\\'s passed out i\\'m REALLY going to pace around my room for HOURS asking myself frantically \"WHAT HAVE I DONE?!\".. Jesus heather, get over it and grow up... and i\\'d like to forward that same sentiment to the idiot producers... and while i\\'m at it, instead of this movie being all about an pathetic excuse for a coming out story, perhaps it would have been more suitable to focus the plot onto a character who\\'s mentally unstable... like your so-called \"lesbian\" character... after all, i know the first time i had gay sex, when i left the next morning i jumped to the sky in excitement in the middle of the street... honestly b*tch, get a grip... <br /><br />WHAT A JOKE! and please note there are many many many more flaws and appallingly stupid aspects to this lame flick, but i\\'m so sick of even thinking about it anymore. bottom line, if you\\'re a smart person you\\'ll hate this movie, and if you\\'re not a smart person, then you\\'ll love it... it\\'s as simple as that.' 0\n",
      "b\"Who wouldn't want to go on road trip with Peter Falk? That guy's right eye has more character than most actors today. This is the kind of funny and touching movie we are all looking for as a counterbalance to all the bombastic special effects bores. Women are going to love it for all the wake-up romance advice for men, and men will love it for its spot-on father/son character study--one great little scene after another. And it has just enough of an edge to be a true indie find. Obviously this is a labor of love for Paul Reiser who understands what it's like to be both a father and a son, as well as to have both laughter and tears as you move through life. The most fun part, though, was watching Reiser watch Falk. You could tell it was both his character coming to a new appreciation of his father and a fellow actor really enjoying Peter Falk's special craft. Really delightful. Let's hope this film makes it into theaters around the country sometime soon so everyone can have a chance to laugh and cry with Paul Reiser and folks.\" 1\n",
      "b'\"They were always trying to get me killed,\" Alec Guinness once wrote of The Man In the White Suit\\'s technicians. \"They thought actors got in the way of things.\" He went on to describe how he\\'d been given a wire rope to climb down and, assured it was safe, narrowly avoided serious injury when it suddenly snapped mid-descent.<br /><br />\"People get in the way of things\" might be a maxim tailor-made for White Suit inventor Sidney Stratton (fittingly played blank slate-fashion by Alec Guinness) in Alexander Mackendrick\\'s definitive Ealing film of 1951. Certainly, he cares only about his work, its realisation - and sod the consequences. And similarly, with the exception of a couple of peripheral characters, there\\'s almost nobody to root for in this chilly satire on capital and labour.<br /><br />Told in flashback, the film concerns Stratton\\'s invention of a dirt-resistant, everlasting fibre (fashioned into the white suit of the title), and subsequent attempts by the clothing industry and its unions to suppress it.<br /><br />While the industry fears the bottom will drop out of the market, the shop floor stewards worry about finding themselves out of a job. Abduction and bribery attempts follow, with both money and an industry chief\\'s daughter on offer (Daphne, the delectable, 4-packs-a-day-voiced Joan Greenwood), to the tragi-comic end.<br /><br />\"What\\'s to become of my bit of washing when there\\'s no washing to do?\" bemoans Stratton\\'s landlady near the close. A notion Stratton hadn\\'t even considered - and has disregarded again by the movie\\'s ambiguous coda.<br /><br />A superior, if decidedly downbeat comedy, expertly performed - and pretty much answering the oft-raised question of whatever happened to the everlasting light bulb and the car that ran on water...' 1\n",
      "b\"I saw a special advance screening of this today. I have to let you know, I'm not a huge fan of either Dane Cook or Steve Carell, so I really had no expectations going into this. I ended up enjoying it quite a bit.<br /><br />Dan in Real Life is the story of a widower with 3 daughters who goes to spend a weekend with his family. While at a bookstore, he meets the woman of his dreams, only to find out that she happens to be his brother's girlfriend.<br /><br />This movie is pretty well made- the soundtrack, cinematography, and acting are all top-notch, especially Steve Carell. My problem with it was mostly that there seemed to be a lack of character development, mostly with Dane Cook's character. We never really get a close look at the relationship between Dane and Steve's characters, and I felt that it could have helped a bit in showing what Dan's inner conflict about being in love with Dane's girlfriend was like. Other than this though, Dan in Real Life is definitely a solid, sweet film- definitely a nice break from all the horror and action movies we've been getting this year.\" 1\n"
     ]
    }
   ],
   "source": [
    "for review in ds_train_raw.take(5).as_numpy_iterator():\n",
    "    print(review[0][0], review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6847083",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = tfds.features.text.TokenTextEncoder(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "545957c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text_tensor, label):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text = text_encoder.encode(text)\n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a545d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 2, 3, 4, 5, 6, 2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 5, 12, 2, 32, 33, 17, 34, 35, 36, 5, 37, 24, 38, 39, 5, 37, 36, 40, 2, 41, 42, 4, 43, 44, 29, 5, 45, 46, 47, 48, 49, 5, 50, 24, 51, 52, 5, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 61, 59, 63, 64, 65, 66, 29, 5, 67, 68, 5, 63, 29, 5, 69, 30, 70, 2, 71, 8, 72, 73, 74, 29, 75, 76, 77, 78, 59, 79, 80, 81, 82, 5, 83, 78, 24, 84, 5, 85, 86, 5, 87, 36, 5, 24, 81, 88, 89, 5, 90, 91, 92, 56, 29, 93, 5, 53, 54, 94, 95, 96, 36, 97, 5, 98, 36, 5, 99, 81, 68, 5, 24, 10, 100, 101, 40, 5, 102, 54, 5, 12, 103, 54, 11, 104, 105, 106, 5, 107, 36, 108, 29, 109, 5, 110, 5, 111, 112, 24], <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "([113, 114, 115, 116, 117, 11, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 5, 128, 36, 5, 6, 129, 130, 131, 5, 132, 133, 134, 135, 6, 136, 137, 138, 54, 61, 139, 61, 136, 13, 140, 141, 6, 34, 10, 142, 57, 136, 143, 144, 8, 145, 146, 124, 147, 29, 148, 149, 5, 150, 36, 17, 12, 151, 152, 152, 153, 136, 154, 113, 114, 136, 155, 156, 11, 157, 158, 10, 159, 160, 21, 161, 162, 136, 154, 163, 164, 8, 165, 166, 167, 168, 78, 169, 170, 9, 171, 172, 173, 2, 174, 175, 176, 177, 178, 125, 29, 179, 146, 29, 136, 180, 16, 8, 181, 57, 182, 183, 8, 5, 184, 128, 29, 159, 136, 154, 185, 125, 186, 36, 17, 6, 187, 40, 188, 189, 190, 191, 78, 11, 192, 162, 25, 193, 125, 194, 41, 195, 196, 197, 8, 198, 5, 199, 200, 11, 201, 202, 21, 203, 204, 16, 205, 10, 112, 119, 201, 31, 40, 136, 206, 5, 207, 208, 136, 209, 210, 211, 212, 136, 213, 5, 214, 215, 136, 216, 8, 5, 217, 54, 218, 54, 5, 219, 36, 5, 220, 221, 222, 223, 177, 11, 224, 152, 152, 172, 225, 226, 29, 227, 228, 229, 131, 230, 230, 230, 196, 231, 29, 232, 233, 234, 8, 17, 235, 236, 237, 136, 154, 10, 238, 36, 30, 239, 188, 125, 240, 241, 242, 120, 243, 244, 11, 245, 246, 243, 247, 248, 17, 6, 29, 120, 243, 244, 249, 11, 245, 246, 250, 243, 247, 24, 125, 125, 21, 61, 251, 61, 57], <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "([126, 252, 116, 71, 8, 253, 124, 254, 255, 256, 257, 258, 259, 260, 21, 261, 262, 263, 196, 201, 264, 134, 99, 265, 141, 34, 5, 266, 36, 267, 29, 268, 6, 51, 131, 40, 269, 78, 61, 11, 270, 8, 40, 5, 271, 272, 273, 274, 275, 131, 164, 8, 24, 125, 78, 40, 5, 276, 146, 277, 278, 78, 279, 29, 279, 280, 24, 125, 78, 281, 282, 124, 283, 284, 201, 285, 35, 286, 287, 288, 31, 289, 96, 125, 263, 155, 290, 36, 189, 291, 8, 14, 11, 292, 293, 294, 295, 17, 34, 11, 296, 36, 24, 78, 297, 298, 202, 299, 300, 125, 21, 16, 8, 14, 301, 11, 283, 29, 11, 284, 61, 62, 61, 8, 41, 301, 302, 29, 303, 61, 243, 304, 305, 122, 43, 134, 306, 307, 308, 309, 49, 298, 310, 258, 311, 312, 313, 125, 309, 301, 314, 201, 192, 8, 11, 315, 316, 36, 314, 283, 29, 11, 317, 318, 319, 320, 257, 258, 21, 272, 321, 322, 323, 324, 21, 325, 17, 12, 68, 125, 326, 327, 166, 5, 328, 329, 330, 10, 331, 13, 41, 11, 332, 8, 333, 29, 334, 256, 297, 298, 29, 335], <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "([336, 337, 338, 339, 8, 177, 27, 340, 341, 342, 343, 344, 36, 43, 345, 346, 5, 347, 348, 21, 349, 336, 350, 99, 351, 54, 5, 105, 36, 352, 353, 354, 124, 8, 355, 356, 357, 180, 195, 358, 11, 359, 360, 8, 361, 362, 29, 363, 125, 309, 364, 365, 366, 367, 368, 212, 125, 369, 370, 371, 372, 152, 152, 373, 177, 54, 5, 105, 36, 352, 374, 14, 11, 375, 376, 15, 78, 347, 348, 377, 378, 379, 380, 381, 382, 383, 384, 385, 341, 342, 54, 386, 387, 21, 388, 389, 12, 36, 390, 391, 357, 392, 393, 188, 314, 394, 281, 395, 29, 396, 5, 397, 96, 398, 256, 5, 399, 36, 11, 400, 36, 401, 53, 229, 21, 402, 403, 8, 404, 78, 54, 17, 405, 406, 124, 407, 29, 408, 152, 152, 409, 54, 410, 5, 12, 411, 379, 21, 412, 36, 11, 413, 414, 415, 416, 417, 326, 5, 418, 419, 36, 5, 420, 29, 421, 422, 385, 5, 423, 424, 29, 281, 425, 8, 426, 125, 152, 152, 427, 5, 424, 428, 5, 241, 280, 429, 162, 36, 5, 430, 5, 431, 432, 433, 434, 188, 435, 436, 162, 36, 11, 437, 438, 29, 439, 422, 440, 256, 301, 441, 29, 189, 424, 442, 21, 443, 124, 444, 445, 5, 446, 447, 448, 11, 449, 450, 451, 452, 8, 5, 453, 454, 455, 152, 152, 456, 21, 8, 457, 36, 167, 458, 36, 459, 212, 229, 21, 460, 459, 8, 127, 461, 379, 21, 462, 463, 5, 464, 225, 465, 379, 466, 116, 30, 467, 29, 263, 468, 469, 385, 5, 6, 21, 470, 471, 152, 152, 225, 472, 120, 473, 474, 475, 476, 477, 29, 478, 479, 480, 5, 481, 482, 483, 36, 484, 485, 8, 5, 415, 486, 487, 29, 5, 488, 57, 489, 124, 490], <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "([2, 491, 11, 272, 492, 493, 36, 17, 265, 2, 41, 8, 494, 243, 206, 2, 154, 249, 11, 495, 496, 36, 497, 498, 499, 500, 501, 502, 10, 2, 319, 209, 460, 503, 164, 326, 17, 2, 504, 146, 320, 125, 505, 11, 458, 152, 152, 506, 54, 507, 508, 34, 5, 25, 36, 11, 509, 256, 510, 511, 202, 512, 8, 513, 11, 514, 256, 314, 515, 427, 185, 11, 516, 357, 517, 5, 518, 36, 314, 519, 393, 8, 294, 162, 57, 160, 520, 8, 14, 314, 521, 21, 522, 152, 152, 141, 6, 34, 478, 62, 15, 5, 523, 80, 29, 524, 131, 40, 525, 526, 527, 501, 502, 528, 529, 256, 125, 309, 530, 57, 229, 531, 8, 14, 11, 532, 36, 201, 533, 530, 256, 498, 499, 21, 201, 534, 535, 319, 177, 11, 464, 536, 185, 5, 537, 538, 498, 29, 501, 21, 53, 29, 2, 143, 57, 125, 312, 41, 539, 11, 458, 54, 540, 300, 506, 21, 541, 542, 188, 187, 54, 24, 256, 498, 21, 522, 309, 16, 543, 264, 17, 308, 506, 54, 507, 508, 34, 544, 11, 545, 546, 12, 544, 11, 547, 548, 549, 40, 5, 550, 29, 551, 38, 51, 137, 195, 552, 17, 553], <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for review in ds_train_raw.take(5):\n",
    "    print(encode_text(review[0], review[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edd8c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_map(text_tensor, label):\n",
    "    return tf.py_function(encode_text, inp=[text_tensor, label], Tout=[tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9aaa0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_encoded = ds_train_raw.map(encode_text_map)\n",
    "ds_valid_encoded = ds_valid_raw.map(encode_text_map)\n",
    "ds_test_encoded = ds_test_raw.map(encode_text_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef7eb9e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   2   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31   5  12   2  32\n",
      "  33  17  34  35  36   5  37  24  38  39   5  37  36  40   2  41  42   4\n",
      "  43  44  29   5  45  46  47  48  49   5  50  24  51  52   5  53  54  55\n",
      "  56  57  58  59  60  61  62  61  59  63  64  65  66  29   5  67  68   5\n",
      "  63  29   5  69  30  70   2  71   8  72  73  74  29  75  76  77  78  59\n",
      "  79  80  81  82   5  83  78  24  84   5  85  86   5  87  36   5  24  81\n",
      "  88  89   5  90  91  92  56  29  93   5  53  54  94  95  96  36  97   5\n",
      "  98  36   5  99  81  68   5  24  10 100 101  40   5 102  54   5  12 103\n",
      "  54  11 104 105 106   5 107  36 108  29 109   5 110   5 111 112  24] 1\n",
      "[113 114 115 116 117  11 118 119 120 121 122 123 124 125 126 127   5 128\n",
      "  36   5   6 129 130 131   5 132 133 134 135   6 136 137 138  54  61 139\n",
      "  61 136  13 140 141   6  34  10 142  57 136 143 144   8 145 146 124 147\n",
      "  29 148 149   5 150  36  17  12 151 152 152 153 136 154 113 114 136 155\n",
      " 156  11 157 158  10 159 160  21 161 162 136 154 163 164   8 165 166 167\n",
      " 168  78 169 170   9 171 172 173   2 174 175 176 177 178 125  29 179 146\n",
      "  29 136 180  16   8 181  57 182 183   8   5 184 128  29 159 136 154 185\n",
      " 125 186  36  17   6 187  40 188 189 190 191  78  11 192 162  25 193 125\n",
      " 194  41 195 196 197   8 198   5 199 200  11 201 202  21 203 204  16 205\n",
      "  10 112 119 201  31  40 136 206   5 207 208 136 209 210 211 212 136 213\n",
      "   5 214 215 136 216   8   5 217  54 218  54   5 219  36   5 220 221 222\n",
      " 223 177  11 224 152 152 172 225 226  29 227 228 229 131 230 230 230 196\n",
      " 231  29 232 233 234   8  17 235 236 237 136 154  10 238  36  30 239 188\n",
      " 125 240 241 242 120 243 244  11 245 246 243 247 248  17   6  29 120 243\n",
      " 244 249  11 245 246 250 243 247  24 125 125  21  61 251  61  57] 0\n",
      "[126 252 116  71   8 253 124 254 255 256 257 258 259 260  21 261 262 263\n",
      " 196 201 264 134  99 265 141  34   5 266  36 267  29 268   6  51 131  40\n",
      " 269  78  61  11 270   8  40   5 271 272 273 274 275 131 164   8  24 125\n",
      "  78  40   5 276 146 277 278  78 279  29 279 280  24 125  78 281 282 124\n",
      " 283 284 201 285  35 286 287 288  31 289  96 125 263 155 290  36 189 291\n",
      "   8  14  11 292 293 294 295  17  34  11 296  36  24  78 297 298 202 299\n",
      " 300 125  21  16   8  14 301  11 283  29  11 284  61  62  61   8  41 301\n",
      " 302  29 303  61 243 304 305 122  43 134 306 307 308 309  49 298 310 258\n",
      " 311 312 313 125 309 301 314 201 192   8  11 315 316  36 314 283  29  11\n",
      " 317 318 319 320 257 258  21 272 321 322 323 324  21 325  17  12  68 125\n",
      " 326 327 166   5 328 329 330  10 331  13  41  11 332   8 333  29 334 256\n",
      " 297 298  29 335] 1\n",
      "[336 337 338 339   8 177  27 340 341 342 343 344  36  43 345 346   5 347\n",
      " 348  21 349 336 350  99 351  54   5 105  36 352 353 354 124   8 355 356\n",
      " 357 180 195 358  11 359 360   8 361 362  29 363 125 309 364 365 366 367\n",
      " 368 212 125 369 370 371 372 152 152 373 177  54   5 105  36 352 374  14\n",
      "  11 375 376  15  78 347 348 377 378 379 380 381 382 383 384 385 341 342\n",
      "  54 386 387  21 388 389  12  36 390 391 357 392 393 188 314 394 281 395\n",
      "  29 396   5 397  96 398 256   5 399  36  11 400  36 401  53 229  21 402\n",
      " 403   8 404  78  54  17 405 406 124 407  29 408 152 152 409  54 410   5\n",
      "  12 411 379  21 412  36  11 413 414 415 416 417 326   5 418 419  36   5\n",
      " 420  29 421 422 385   5 423 424  29 281 425   8 426 125 152 152 427   5\n",
      " 424 428   5 241 280 429 162  36   5 430   5 431 432 433 434 188 435 436\n",
      " 162  36  11 437 438  29 439 422 440 256 301 441  29 189 424 442  21 443\n",
      " 124 444 445   5 446 447 448  11 449 450 451 452   8   5 453 454 455 152\n",
      " 152 456  21   8 457  36 167 458  36 459 212 229  21 460 459   8 127 461\n",
      " 379  21 462 463   5 464 225 465 379 466 116  30 467  29 263 468 469 385\n",
      "   5   6  21 470 471 152 152 225 472 120 473 474 475 476 477  29 478 479\n",
      " 480   5 481 482 483  36 484 485   8   5 415 486 487  29   5 488  57 489\n",
      " 124 490] 1\n",
      "[  2 491  11 272 492 493  36  17 265   2  41   8 494 243 206   2 154 249\n",
      "  11 495 496  36 497 498 499 500 501 502  10   2 319 209 460 503 164 326\n",
      "  17   2 504 146 320 125 505  11 458 152 152 506  54 507 508  34   5  25\n",
      "  36  11 509 256 510 511 202 512   8 513  11 514 256 314 515 427 185  11\n",
      " 516 357 517   5 518  36 314 519 393   8 294 162  57 160 520   8  14 314\n",
      " 521  21 522 152 152 141   6  34 478  62  15   5 523  80  29 524 131  40\n",
      " 525 526 527 501 502 528 529 256 125 309 530  57 229 531   8  14  11 532\n",
      "  36 201 533 530 256 498 499  21 201 534 535 319 177  11 464 536 185   5\n",
      " 537 538 498  29 501  21  53  29   2 143  57 125 312  41 539  11 458  54\n",
      " 540 300 506  21 541 542 188 187  54  24 256 498  21 522 309  16 543 264\n",
      "  17 308 506  54 507 508  34 544  11 545 546  12 544  11 547 548 549  40\n",
      "   5 550  29 551  38  51 137 195 552  17 553] 1\n"
     ]
    }
   ],
   "source": [
    "for review in ds_train_encoded.take(5).as_numpy_iterator():\n",
    "    print(review[0], review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a26abed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train_encoded.padded_batch(32, padded_shapes=([-1],[]))\n",
    "ds_valid = ds_valid_encoded.padded_batch(32, padded_shapes=([-1],[]))\n",
    "ds_test = ds_test_encoded.padded_batch(32, padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a936f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   2   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31   5  12   2  32\n",
      "  33  17  34  35  36   5  37  24  38  39   5  37  36  40   2  41  42   4\n",
      "  43  44  29   5  45  46  47  48  49   5  50  24  51  52   5  53  54  55\n",
      "  56  57  58  59  60  61  62  61  59  63  64  65  66  29   5  67  68   5\n",
      "  63  29   5  69  30  70   2  71   8  72  73  74  29  75  76  77  78  59\n",
      "  79  80  81  82   5  83  78  24  84   5  85  86   5  87  36   5  24  81\n",
      "  88  89   5  90  91  92  56  29  93   5  53  54  94  95  96  36  97   5\n",
      "  98  36   5  99  81  68   5  24  10 100 101  40   5 102  54   5  12 103\n",
      "  54  11 104 105 106   5 107  36 108  29 109   5 110   5 111 112  24   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "[   2 2105 1919 2106   34  289 2107  385 2108 1281 2109 2110  540    5\n",
      " 1582 1408   36 2111   11 2112 2113  518  576   32   41  195  189 2114\n",
      " 2115    8 1166    5  134 2116 2117 2118 2119 2120   29  121 1051   29\n",
      "  109  612   11  631  124   17 2121 2122  280 2123   17   34   11  631\n",
      " 2124  125   21  249   61  142   61  125   21 2125  631 2126   36 2105\n",
      "  237  125   21  155   61  142  152  152  576 2127   27   36   11 2128\n",
      "  549    5 2129   21  631  346 2130 2131 1442 2132 2133 2134  309 2135\n",
      "    5 2136 2137 2138  124   43 2105 2139 2111  631   29  357 1942 2140\n",
      " 2141   78   11 2142 2137 2143   36  356    5 2142  309 2144  237  356\n",
      "    5 2113 1051  956 2145   54  141  631 2127   27   36   57  152  152\n",
      "   43  279  131 2146   29  358 2021    8 2147  436   29    5  518   57\n",
      "  130  131 2111  196    2  194  129  189 2148 1267  269    8 2142  189\n",
      " 2148  518  194  647 2149  121   29  121 1051    8  109  243   11  968\n",
      "   57   34   10 2150  243  247 2151 2076 1109  208  243 2152  124  733\n",
      "  237  906  131 1930 2153   99   10  949 1982  152  152  576 2154   27\n",
      "    8 2155  300   34   10 1582  188   40   36   17   43 1474   57   17\n",
      "   34   61  896   61  121 2156 2157 2158 2159 2160   36 2161   29 2162\n",
      "   36 2163   36 2164   54 2165  208   78    5 2121  572  243   13  116\n",
      "  248  612   78  339    8  148   11 2166 2167    5 2168   34  202  194\n",
      "   71    8   14  256   17  518 2169  189  885 2170 2168  120  160   29\n",
      "  121 1051   21  214  631  194   14  124    5 2171 2006  105  243 2172\n",
      "  125  125   21   11 2173 2174  243  137  138 2175  724  866   10  385\n",
      "  753    5 2176  986   34  362    8 2177  152  152  992 2178  500 1241\n",
      "  280  148   17   11  196 2179 2173 2174  500  908 1444  549  908   36\n",
      "    5 1805 2180    8    5 2181 1247 2182   29   78  937 2183  189  455\n",
      "    8 2153   93   17   34  155  289 2184   54    5 2185   61    8  949\n",
      "  130 1455  455 2186    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "[ 992  196 3521 3522   29 3523   78  121  152  152  141  287 3524  475\n",
      " 3525   89  549  288    8  288  256   11 1557 3526 3527  700 1532  976\n",
      "   29   11 3249 1814 1310   36   17   34 3528  166    5 1494   36    5\n",
      " 2663   21  202   34  269    8  548  162   36    5 3529  381  385 3530\n",
      " 3531  160   34 1979  625 3532    5 2731  279   41   11 3533 3534   57\n",
      "   34  118   29   36   97 3531   34  104   54   40 2864   36   95  549\n",
      " 3535    8 3536    8 3537  152  152 3538   40    5 3539   29 2349 3540\n",
      "   34   57  796  367  529   36 3541   54   24   29  249 3542   54   24\n",
      "  893   21   11  287 3543  237  659 3544   34  124  525   36 1348  125\n",
      " 3545   29 1179   54   40   48  256  230 1277  549   17 3546    5 3547\n",
      "  127  249  155  313  300  130  131 3548  500  239  237 3549  109   11\n",
      "  266   36 3550 3551   61  120    8 3552    5 3553  500 3554   96  229\n",
      "   34   57 3555 3556  625 3269  585  817    5 3557 3558  237  125   21\n",
      "  307   36    5 3559  616   29  125   21  266   36 3560  152  152  741\n",
      "  243  131  269   78 3561  500 3562 3563  243 1298  116  294  125  625\n",
      "  987   61   11   25   62  706   29 1037  256 3564   29 3565  125   21\n",
      "  319   11  286 1137   43  839  374  249  886   61   11  783 3566  237\n",
      "  125   21 1285   11 2366   24   25 1078  402   11 3567  757  714  125\n",
      "   21   11 3568   96  667    2  491 3531  309  104    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 572 5029 5030 1067 5031 4229  351   11 2337 2458   54 5032   29 3154\n",
      "    5  530 5033 5034    2  137 1155    8  125   29    5 5035 5036 2337\n",
      " 2458    2  115  116 4336  237 1852  125  146  908 5037 5038   12   34\n",
      "  585  264  134 2550 5037 5038 1277   54  167  867 2529 5039 1340  503\n",
      "  337  189 4096  726    2  309  505 5040 4021    8  294    5   12  478\n",
      " 2723  152  152 3179 5041   34 3496   11 2856   36 5042  202  337  751\n",
      "   54   11 5043   57 5044    5 5045   29    5 2353   21  525 5046   34\n",
      " 5047  256 5048    5 5049  141  615  116 1166  825  139  237    5 1282\n",
      "   34  249   35  357 4825    8  941 4547 5050 3920   51 2546  949   29\n",
      "    5  560   36    5 5046   29    5 5041   29   36    5 5043  152  152\n",
      "   43   12   34 5051 5052   78   11 5053   12   29 5054  367   54 2613\n",
      "  460 1173  616  475 1337    8   14  794  625   43   25   13   14   11\n",
      "  287  998    8  440  185  207  237   40   68 1448 2800   43   12  512\n",
      "   11  458 5055  185    5  455  237  460 2898  264   11 5056 5057   12\n",
      "  374  127   29   78    5  134  307    2  794  125 2723   43  752 2480\n",
      "  131  586  256  700  740   80    8 3943  125   43 2279  976 2068  116\n",
      "  146    8    5 5058   36    5  585 1173 5037 5038 1277  237  193  130\n",
      "  244  249 5059    8   14    5 4876  131  196 1461   54   57  130  244\n",
      " 1771   16 5060 2454 5061  237  229   21  700 5062   29 5063 5064   57\n",
      " 1272    5   12   54 5037 5038 5065   43   12  615  116   41    5   37\n",
      " 1397  878  256    5 2848  187   11 5066 3108   54 5067   29 5068  998\n",
      "    8 5069  549  931 1026  893   21   11 1377 1809   54    5   12   57\n",
      "    2  607  116  129    2  137  138  866  237   68    5   37 3697   36\n",
      "  908   36    5 5070 1397  249  155  726  243   52  121 5071  500  193\n",
      "  125   34 5072   43   12 5073    5 5067   29 1996   36    5  585 1173\n",
      " 5037 5038 1277   29  193    5 3705  618  237    2  393 5074 1173  194\n",
      "  148  612  884   17  740  240 5075 5076  723  737  249  109   27  325\n",
      "   57   57   21  188    8 2361  908  208  330  308 5077 5078 2031  978\n",
      "  263  125   54  948  120  357   13  177    5 5079   29 1397 5029 5030\n",
      " 1067 5031   34  249  164    8  253  200  167 3239   36 1778 5037 5038\n",
      "  385  908  595  237  125   21   11  834 5080  585  264 5081 5082  500\n",
      " 5083  682 1067 5084 5085  193  585  264 5086  618  308    2  667   16\n",
      "   57   12  505   11  458  196  124   11 1226 2300  295  125   21 1832\n",
      "  463    5 1575 5087  237  125   21   11 1444 5016 5088  319 5089  280\n",
      " 3269  177   11 1226 2300 4155 1780  757   81   34  193    5   37 5090\n",
      "   36  356  479    2  599  125 3257  608    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[3965  549 6093 ...    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "for review in ds_train.take(5).as_numpy_iterator():\n",
    "    print(review[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd73b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00113706",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9a01092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Bidirectional, GRU, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d2c3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_counts) + 2\n",
    "embedding_size = 32\n",
    "conv_bidir_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aef840c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfbd46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.add(MaxPooling1D(pool_size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c9bf562",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.add(Bidirectional(LSTM(units=16, dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82c410b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.add(LSTM(units=32, dropout=0.5, recurrent_dropout=0.5, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "936f05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.add(Dense(64, activation='relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb46e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d1f05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          2791616   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         12416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 32)          18560     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,833,089\n",
      "Trainable params: 2,833,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_bidir_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c4150ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bidir_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d3c9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6def5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir='.\\logs\\conv_bidir_lstm_model', histogram_freq=1, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b19c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "  1/625 [..............................] - ETA: 0s - loss: 0.6945 - accuracy: 0.4062WARNING:tensorflow:From C:\\Users\\shdmp\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "625/625 [==============================] - 252s 403ms/step - loss: 0.6934 - accuracy: 0.4967 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 2/8\n",
      "625/625 [==============================] - 252s 403ms/step - loss: 0.6910 - accuracy: 0.5167 - val_loss: 0.6909 - val_accuracy: 0.5010\n",
      "Epoch 3/8\n",
      "625/625 [==============================] - 242s 387ms/step - loss: 0.6857 - accuracy: 0.5239 - val_loss: 0.6939 - val_accuracy: 0.4964\n",
      "Epoch 4/8\n",
      "625/625 [==============================] - 259s 414ms/step - loss: 0.6460 - accuracy: 0.5655 - val_loss: 0.4463 - val_accuracy: 0.8142\n",
      "Epoch 5/8\n",
      "625/625 [==============================] - 241s 385ms/step - loss: 0.3294 - accuracy: 0.8624 - val_loss: 0.3191 - val_accuracy: 0.8714\n",
      "Epoch 6/8\n",
      "625/625 [==============================] - 255s 407ms/step - loss: 0.1663 - accuracy: 0.9416 - val_loss: 0.3511 - val_accuracy: 0.8794\n",
      "Epoch 7/8\n",
      "625/625 [==============================] - 259s 414ms/step - loss: 0.0854 - accuracy: 0.9746 - val_loss: 0.3821 - val_accuracy: 0.8812\n",
      "Epoch 8/8\n",
      "625/625 [==============================] - 256s 409ms/step - loss: 0.0453 - accuracy: 0.9888 - val_loss: 0.5327 - val_accuracy: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x287ecbb9e80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_bidir_lstm_model.fit(ds_train, epochs=8, validation_data=ds_valid, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a62aa28e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 50s 64ms/step - loss: 0.5140 - accuracy: 0.8784\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = conv_bidir_lstm_model.evaluate(ds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
